# KBot Trainer - Test & Vergleich Anleitung

## ğŸ§ª Wie man beide Versionen vergleicht

### Option 1: Schneller Test mit kleinem Datensatz

```bash
# Alte Version (JaegerBot):
# (in Backup speichern wenn noch vorhanden)
cp kbot/src/kbot/analysis/trainer.py kbot/src/kbot/analysis/trainer_new.py
# Alte Version wiederherstellen aus JaegerBot:
cp jaegerbot/src/jaegerbot/analysis/trainer.py kbot/src/kbot/analysis/trainer_old.py

# Neue Version testen:
cd kbot
python3 src/kbot/analysis/trainer.py \
  --symbols BTC \
  --timeframes 15m \
  --start_date 2024-01-01 \
  --end_date 2024-03-01

# Output speichern:
# Notiere: Genauigkeit, Feature-Count, Training-Zeit
```

### Option 2: Paralleler Test mit unterschiedlichen Datenmengen

```bash
# Test 1: 3 Monate
python3 src/kbot/analysis/trainer.py \
  --symbols BTC \
  --timeframes 15m \
  --start_date 2024-10-01 \
  --end_date 2024-12-31
# â†’ Neue Genauigkeit: X%
# â†’ Training-Zeit: Y Min

# Test 2: 6 Monate
python3 src/kbot/analysis/trainer.py \
  --symbols BTC \
  --timeframes 15m \
  --start_date 2024-07-01 \
  --end_date 2024-12-31
# â†’ Neue Genauigkeit: X+Z%
# â†’ Training-Zeit: Y+W Min

# Test 3: 1 Jahr
python3 src/kbot/analysis/trainer.py \
  --symbols BTC \
  --timeframes 15m \
  --start_date 2023-12-01 \
  --end_date 2024-12-31
# â†’ Neue Genauigkeit: X+Z+K%
# â†’ Training-Zeit: Y+W+L Min
```

---

## ğŸ“Š VERGLEICH CHECKLIST

### Performance Metrics
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Metrik                    â”‚  ALTE    â”‚  NEUE    â”‚ Diff  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Trainings-Zeit (3 Monate)  â”‚ ___min   â”‚ ___min   â”‚ ___% â”‚
â”‚  Trainings-Zeit (6 Monate)  â”‚ ___min   â”‚ ___min   â”‚ ___% â”‚
â”‚  Trainings-Zeit (1 Jahr)    â”‚ ___min   â”‚ ___min   â”‚ ___% â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Genauigkeit (3 Monate)     â”‚ ___%     â”‚ ___%     â”‚ ___% â”‚
â”‚  Genauigkeit (6 Monate)     â”‚ ___%     â”‚ ___%     â”‚ ___% â”‚
â”‚  Genauigkeit (1 Jahr)       â”‚ ___%     â”‚ ___%     â”‚ ___% â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Features trainiert         â”‚ 31       â”‚ 38+      â”‚ +7   â”‚
â”‚  ATF Features               â”‚ 0        â”‚ 8        â”‚ +8   â”‚
â”‚  CCI                        â”‚ Nein     â”‚ Ja       â”‚ +1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Optimizer Test (wichtig!)
```bash
# Mit neuen Modellen optimieren:
cd kbot
./run_pipeline.sh
# â†’ Wahle: BTC 15m
# â†’ Wahle: 3 Monate Lookback
# â†’ Speichere beste Config

# Notiere:
# - Best Profit: __%
# - Best Sharpe: __
# - Min Drawdown: __%
# - Win Rate: __%
```

---

## ğŸ¯ Erwartete Unterschiede

### Training-Zeit
```
Alte Version:  ~8 Minuten (fÃ¼r 1 Jahr BTC 15m)
Neue Version: ~12 Minuten (fÃ¼r 1 Jahr BTC 15m)
Grund: +7 Features = ~50% mehr Berechnung
```

### Modell-Genauigkeit
```
Alte Version:  ~55-60% (baseline)
Neue Version: ~57-63% (mit 38+ Features)
Hoffnung: +2-3% besser durch ATF
```

### Memory & Disk
```
Alte Version:  ~50 MB pro Modell
Neue Version: ~55 MB pro Modell
(Minimal unterschied)
```

---

## ğŸ“ˆ Optimizer Output Vergleich

Nach Training sollte man mit `run_pipeline.sh` testen:

### Mit ALTEN Modellen:
```
======================================================
   KBot Parameter-Optimierung: BTC 15m
======================================================

âœ“ Beste Strategie gefunden:
  - Profit:      12.5%
  - Sharpe:      1.2
  - Drawdown:    -8.3%
  - Win-Rate:    56%
```

### Mit NEUEN Modellen (erwartet):
```
======================================================
   KBot Parameter-Optimierung: BTC 15m
======================================================

âœ“ Beste Strategie gefunden:
  - Profit:      14.2%     â† +1.7% (besser!)
  - Sharpe:      1.35      â† +0.15 (besser!)
  - Drawdown:    -7.1%     â† Weniger (besser!)
  - Win-Rate:    58%       â† +2% (besser!)
```

---

## ğŸ” DEBUGGING wenn Neue Version schlechter ist

Falls die neue Version NICHT besser ist, Ã¼berprÃ¼fe:

### 1. Feature Validation
```bash
# In Python REPL:
from kbot.utils import ann_model
from kbot.analysis.backtester import load_data

data = load_data("BTC/USDT:USDT", "15m", "2024-01-01", "2024-12-31")
X, y = ann_model.prepare_data_for_ann(data, "15m")

print(f"Features: {len(X.columns)}")
print(f"Feature-Namen: {list(X.columns)}")
print(f"Missing values: {X.isnull().sum().sum()}")
```

### 2. ATF Probleme
```bash
# ATF-Features Ã¼berprÃ¼fen:
print(X[['atf_pearson_r', 'atf_trend_strength', 'atf_slope']])
# Sollten NOT alle 0 sein!
```

### 3. Hyperparameter anpassen
```python
# In ann_model.py build_and_train_model():
# Versuche:
# - Kleinere Learning Rate: 0.0001 statt 0.0005
# - Mehr Dropout: 0.4 statt 0.3
# - Weniger Epochs: 100 statt 150
```

---

## âœ… ENTSCHEIDUNGS-BAUM

```
         Trainiere neue Version
                  |
          Vergleiche Genauigkeit
               /        \
           Besser?     Gleich?      Schlechter?
            /              |             \
        âœ… NEUEN         âš ï¸ TESTS      âŒ DEBUG
      BEHALTEN         MEHR DATEN      â†’ Siehe oben
                                          oder
                                     Alte Version
                                       BEHALTEN
```

---

## ğŸš€ ROLLOUT PLAN

```
Tag 1: Test neue Version
  âœ“ Trainiere mit 3/6/12 Monaten
  âœ“ ÃœberprÃ¼fe Genauigkeit
  âœ“ Teste Optimizer-Output

Tag 2: Entscheidung
  Option A: Neue Version ist besser
    âœ“ Alte Modelle in Backup sichern
    âœ“ Neue Modelle deployten
    âœ“ In run_pipeline.sh verwenden

  Option B: Alte Version ist besser
    âœ“ Neue Version behalten als Backup
    âœ“ Alte Version weiternutzen
    âœ“ ATF-Integration fÃ¼r Zukunft planen

  Option C: Gleich
    âœ“ Neue Version nutzen (besserer Code)
    âœ“ Alte Modelle als Fallback
```

---

## ğŸ“ NOTES

### Pro neue Version:
- ATF wird vollstÃ¤ndig genutzt
- +7 Features sollten helfen
- Besserer Code & Logging
- Zukunftssicher

### Pro alte Version:
- BewÃ¤hrte Architektur
- Schneller Training
- Weniger KomplexitÃ¤t
- Falls neue Version Bugs hat

### Best Case Scenario:
- Neue Version ist 3-5% besser
- Training dauert nur 40% lÃ¤nger (akzeptabel)
- Deployten neue Version
- Alle zufrieden! ğŸ‰

### Worst Case Scenario:
- Neue Version ist 2-3% schlechter
- Trotzdem alte Version behalten
- ATF-Integration fÃ¼r nÃ¤chste Iteration planen
- Nicht tragisch, wir lernen daraus

---

## ğŸ“ SUPPORT

Falls wÃ¤hrend dem Vergleich Probleme auftreten:

1. **ATF-Fehler**: ÃœberprÃ¼fe `calculate_adaptive_trend_features()` in ann_model.py
2. **Features fehlen**: ÃœberprÃ¼fe feature_cols Liste
3. **Training abstÃ¼rzt**: ÃœberprÃ¼fe Datenmenge und Memory
4. **Optimizer langsamer**: Mehr Features = naturlich langsamer
5. **Genauigkeit sinkt**: Neue Features manchmal Overfitting, siehe Debugging

Good luck! ğŸš€
