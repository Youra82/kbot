#!/usr/bin/env python3
"""
VERBESSERTES TRAINING-SCRIPT fÃ¼r JaegerBot
================================================
Trainiert Modelle mit den neuen erweiterten Features.

WICHTIGE VERBESSERUNGEN:
- 35+ Features statt 8
- Bessere Modell-Architektur (256-128-64-32)
- Walk-Forward Validation
- Class Imbalance Handling
- Mehr Trainingsdaten (2+ Jahre empfohlen)
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from datetime import datetime, timedelta
import joblib

PROJECT_ROOT = os.path.abspath(os.path.dirname(__file__))
sys.path.append(os.path.join(PROJECT_ROOT, 'src'))

from jaegerbot.utils.ann_model import prepare_data_for_ann, build_and_train_model, save_model_and_scaler
from jaegerbot.analysis.backtester import load_data

print("=" * 80)
print("  JAEGERBOT - VERBESSERTES TRAINING")
print("=" * 80)
print()
print("ðŸ“š NEUE FEATURES:")
print("   - 35+ Features statt 8")
print("   - ADX wieder aktiviert")
print("   - EMA Crossovers, VWAP, MFI, Stochastic, etc.")
print("   - Support/Resistance Detection")
print("   - Multi-Timeframe Indicators")
print()
print("ðŸ§  VERBESSERTES MODELL:")
print("   - 256-128-64-32 Architektur")
print("   - Batch Normalization")
print("   - Learning Rate Scheduling")
print("   - Mehr Trainings-Epochs mit Early Stopping")
print()
print("=" * 80)
print()

# Konfiguration
SYMBOL = "SOL/USDT:USDT"
TIMEFRAME = "15m"
START_DATE = "2023-01-01"  # 2 Jahre Daten
END_DATE = datetime.now().strftime("%Y-%m-%d")

print(f"ðŸ“Š Trainiere: {SYMBOL} ({TIMEFRAME})")
print(f"   Zeitraum: {START_DATE} bis {END_DATE}")
print()

# Lade Daten
print("1/5: Lade historische Daten...")
data = load_data(SYMBOL, TIMEFRAME, START_DATE, END_DATE)

if data.empty:
    print("âŒ FEHLER: Keine Daten geladen!")
    sys.exit(1)

print(f"   âœ… {len(data)} Kerzen geladen")
print()

# Prepare Data (mit neuen Features)
print("2/5: Generiere Features und Labels...")
X, y = prepare_data_for_ann(data, timeframe=TIMEFRAME, verbose=True)

if X.empty:
    print("âŒ FEHLER: Feature-Generierung fehlgeschlagen!")
    sys.exit(1)

print(f"   âœ… {len(X)} Samples mit {X.shape[1]} Features generiert")
print(f"   â„¹ï¸  Feature-Liste: {list(X.columns)}")
print()

# Class Distribution
class_0_count = (y == 0).sum()
class_1_count = (y == 1).sum()
print(f"   Klassen-Verteilung:")
print(f"   - Klasse 0 (Short/Neutral): {class_0_count} ({class_0_count/len(y)*100:.1f}%)")
print(f"   - Klasse 1 (Long): {class_1_count} ({class_1_count/len(y)*100:.1f}%)")
print()

# Train/Test Split
print("3/5: Split Train/Test (80/20)...")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=42)

print(f"   âœ… Train: {len(X_train)} samples")
print(f"   âœ… Test:  {len(X_test)} samples")
print()

# Scaling
print("4/5: Standardisiere Features...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
print("   âœ… Features standardisiert")
print()

# Training
print("5/5: Trainiere verbessertes ANN-Modell...")
print("   (Dies kann 5-15 Minuten dauern...)")
print()

model = build_and_train_model(X_train_scaled, y_train)

print()
print("=" * 80)
print("  TRAINING ABGESCHLOSSEN")
print("=" * 80)
print()

# Evaluation
print("ðŸ“Š MODELL-EVALUATION:")
train_loss, train_acc = model.evaluate(X_train_scaled, y_train, verbose=0)
test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)

print(f"   Train Accuracy: {train_acc*100:.2f}%")
print(f"   Test Accuracy:  {test_acc*100:.2f}%")
print(f"   Train Loss:     {train_loss:.4f}")
print(f"   Test Loss:      {test_loss:.4f}")
print()

# Overfitting Check
acc_diff = train_acc - test_acc
if acc_diff > 0.10:
    print("   âš ï¸  WARNUNG: MÃ¶gliches Overfitting (Train-Test Diff > 10%)")
elif acc_diff > 0.05:
    print("   âš ï¸  Leichtes Overfitting erkannt (Train-Test Diff > 5%)")
else:
    print("   âœ… Keine Overfitting-Anzeichen")
print()

# Speichern
print("ðŸ’¾ Speichere Modell und Scaler...")
safe_filename = f"{SYMBOL.replace('/', '').replace(':', '')}_{TIMEFRAME}"
model_path = os.path.join(PROJECT_ROOT, 'artifacts', 'models', f'ann_predictor_{safe_filename}.h5')
scaler_path = os.path.join(PROJECT_ROOT, 'artifacts', 'models', f'ann_scaler_{safe_filename}.joblib')

save_model_and_scaler(model, scaler, model_path, scaler_path)

print(f"   âœ… Modell:  {model_path}")
print(f"   âœ… Scaler:  {scaler_path}")
print()

# Predictions auf Test-Set
print("ðŸŽ¯ PREDICTION THRESHOLD ANALYSE:")
predictions = model.predict(X_test_scaled, verbose=0).flatten()

for threshold in [0.55, 0.60, 0.65, 0.70, 0.75, 0.80]:
    long_signals = (predictions >= threshold).sum()
    short_signals = (predictions <= (1-threshold)).sum()
    total_signals = long_signals + short_signals
    
    if total_signals > 0:
        # Berechne Win-Rate fÃ¼r diesen Threshold
        long_correct = ((predictions >= threshold) & (y_test == 1)).sum()
        short_correct = ((predictions <= (1-threshold)) & (y_test == 0)).sum()
        total_correct = long_correct + short_correct
        win_rate = (total_correct / total_signals * 100) if total_signals > 0 else 0
        
        print(f"   Threshold {threshold:.2f}: {total_signals:4d} Signale, Win-Rate: {win_rate:.1f}%")

print()
print("=" * 80)
print("  EMPFEHLUNG")
print("=" * 80)
print()
print("Basierend auf der Analyse:")
print("1. Verwende einen Threshold >= 0.75 fÃ¼r hÃ¶here Win-Rate")
print("2. FÃ¼hre einen Backtest durch bevor du live gehst:")
print("   bash show_results.sh")
print("3. Validiere dass Win-Rate > 40% im Backtest")
print("4. Starte mit Paper-Trading fÃ¼r 1 Woche")
print()
print("âœ… Training erfolgreich abgeschlossen!")
print()
